---
title: "Final Workflow Assignment"
author: "Mohammad Dastgheib"
date: "3/12/2022"
output:
    html_document:
        toc: true
        toc_float: true
---

This project is based on my master's dissertation [script](https://github.com/mohdasti/PSYC259_Final_Workflow_Project/blob/main/thesisaltogether.Rmd). The original work is in `.Rmd` format. Here, as a follow-up to my previous *self-critique* assignment, I will try to improve my code, as well as illustrating some parts of my code that already follows the goals of this assignment (efficiency, fidelity, sharing/reproducibility)

Before starting the assignment, I need to briefly describe the "original files":
`thesisaltogether.Rmd` is the main file in my original work. `references.bib` and `Rreferences.bib` are bibtex formats for managing my references. `preamble-latex.tex` is an addendum to my YAML section to address some technical issues with the formatting of figures, etc. `Appendix`, `Figures`, and `Raw data` contain several required files to execute the `thesisaltogether.Rmd`. However, the original Raw Data of my work is already posted in my GitHub repo.


# I. Efficiency

## Automation

In the original work, I inserted this function to reduce the amount of time re-installing/loading the packages.

```{}
required_packages <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

packages <- c("rio","readxl", "tidyverse","devtools","dplyr","ggplot2","magrittr","Hmisc","psycho","lmerTest","rstanarm","jtools","bayesplot","corrplot")
required_packages(packages)
```


After examining my initial work, I noticed that I had uploaded my "Raw Data" as an Excel spreadsheet. This means that unless the project is finished, every time I wanted to take a look at my data or running some EDA, I needed to replace the existing Excel file with a new one. This process can be improved if I insert the original works into a Google sheets file and R can have access to that file, which is almost always contains the latest version of my raw data.

### original piece from my work

```{r, include=TRUE, message=FALSE}
# importing the main excel file from Github repository (mohdasti)
RAW_data <- rio::import('https://github.com/mohdasti/Queens-Thesis/blob/master/Raw%20data/RAW_data.xlsx?raw=true', na="N/A")
#View(RAW_data)
```

### improved version with access to the Google Sheets

I have been working on this piece of code for a while for another similar project.



```{}
#creating a function that gets the location of the file (e.g., link) and makes sure that the link is publicly readable or not.
create_Raw_object <-  function(data_location,
                              pdf_mode = FALSE,
                              sheet_is_publicly_readable = TRUE) {

  raw <- list(
    pdf_mode = pdf_mode,
    links = c()
  )

#using stringr function, I look for specific patters of the google docs link. If I found it, then store that in "is_google_sheets_location"

  is_google_sheets_location <- stringr::str_detect(data_location, "docs\\.google\\.com")

  
  if(is_google_sheets_location){
    if(sheet_is_publicly_readable){
# if the original google docs's sharing settings is set to "anyone with link can view", then, it should stop/deauthorize
      googlesheets4::gs4_deauth()
    }
      
# if everything is fine, the the following function will run to read the google sheet. For the sake of simplicity, I assign every column as a character, but later, with specific goals, I can assign col_types with correct attributions.
      
# Here, I imported four columns from that 'raw google sheets' and renamed them in my raw spreadsheet in R      
    read_gsheet <- function(sheet_id){
      googlesheets4::read_sheet(data_location, sheet = sheet_id, skip = 1, col_types = "c")
    }
    raw$Date  <- read_gsheet(sheet_id = "data")
    raw$Participant_ID        <- read_gsheet(sheet_id = "id")
    raw$GMean   <- read_gsheet(sheet_id = "gmean")
    raw$Age  <- read_gsheet(sheet_id = "age")
  }
knitr::opts_chunk$set(
  results='asis',
  echo = FALSE
)

# now, that I have assigned how I can detect the link and specified which columns to be selected and imported to my workspace, I include the link to my google docs.
### the link is fake ###

library(magrittr) # For the pipe
Data <- create_data_object(
  data_location = "https://docs.google.com/spreadsheets/d/....",  
  pdf_mode = params$pdf_mode
)
}

```

